import{_ as o,r as p,o as l,c as i,a as n,b as e,d as a,e as t}from"./app.76e8dadb.js";const r={},c=n("h1",{id:"deep-learning-with-amd-gpu-on-windows",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#deep-learning-with-amd-gpu-on-windows","aria-hidden":"true"},"#"),e(" Deep Learning with AMD GPU on Windows")],-1),d=n("blockquote",null,[n("p",null,"First written\uFF1A2022/09/26"),n("p",null,"Last updated\uFF1A2023/07/15")],-1),u=n("p",null,"In the past\uFF0Cusing AMD GPU for DL\uFF0Cwe need Linux with ROCm installed.",-1),m={href:"https://github.com/microsoft/DirectML",target:"_blank",rel:"noopener noreferrer"},v=t(`<h2 id="how-to-config" tabindex="-1"><a class="header-anchor" href="#how-to-config" aria-hidden="true">#</a> How to config</h2><p>Choose <code>PyTorch-DirectML</code> as an example\uFF1A</p><ol><li><p>(Optional) Install <code>MiniConda</code> environment\uFF0Cand set environment variables\uFF1A</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>Path\\To\\Miniconda3
Path\\To\\Miniconda3\\Scripts
Path\\To\\Miniconda3\\Library\\bin
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Create a <code>Python</code> env\uFF08If without <code>Conda</code>, you also need <code>Python3.8-3.10</code>)</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>conda create <span class="token parameter variable">-n</span> directML <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.8</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li><li><p>Activate env and install dependencies</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>conda activate directML
pip <span class="token function">install</span> torch-directml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Usage</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch_directml
dml <span class="token operator">=</span> torch_directml<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># device=dml</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h2 id="run-an-opensource-project" tabindex="-1"><a class="header-anchor" href="#run-an-opensource-project" aria-hidden="true">#</a> Run an Opensource Project</h2>`,4),h={href:"https://github.com/TencentARC/GFPGAN",target:"_blank",rel:"noopener noreferrer"},b={href:"https://github.com/xinntao/Real-ESRGAN",target:"_blank",rel:"noopener noreferrer"},k={href:"https://github.com/TencentARC/GFPGAN#wrench-dependencies-and-installation",target:"_blank",rel:"noopener noreferrer"},g=t(`<p><strong>Mentioned: If you want to enhance the background, Real-ESRGAN installation is needed</strong></p><p>After Guide, download pre-trained model:</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token function">wget</span> https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth <span class="token parameter variable">-P</span> experiments/pretrained_models
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><blockquote><p>You can use other tools to download to specific directory.</p></blockquote>`,4),_=t(`<li><p>How to use\uFF1A</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>Usage: python inference_gfpgan.py <span class="token parameter variable">-i</span> inputs/whole_imgs <span class="token parameter variable">-o</span> results <span class="token parameter variable">-v</span> <span class="token number">1.3</span> <span class="token parameter variable">-s</span> <span class="token number">2</span> <span class="token punctuation">[</span>options<span class="token punctuation">]</span><span class="token punctuation">..</span>.

  <span class="token parameter variable">-h</span>                   show this <span class="token builtin class-name">help</span>
  <span class="token parameter variable">-i</span> input             Input image or folder. Default: inputs/whole_imgs
  <span class="token parameter variable">-o</span> output            Output folder. Default: results
  <span class="token parameter variable">-v</span> version           GFPGAN model version. Option: <span class="token number">1</span> <span class="token operator">|</span> <span class="token number">1.2</span> <span class="token operator">|</span> <span class="token number">1.3</span>. Default: <span class="token number">1.3</span>
  <span class="token parameter variable">-s</span> upscale           The final upsampling scale of the image. Default: <span class="token number">2</span>
  <span class="token parameter variable">-bg_upsampler</span>        background upsampler. Default: realesrgan
  <span class="token parameter variable">-bg_tile</span>             Tile size <span class="token keyword">for</span> background sampler, <span class="token number">0</span> <span class="token keyword">for</span> no tile during testing. Default: <span class="token number">400</span>
  <span class="token parameter variable">-suffix</span>              Suffix of the restored faces
  <span class="token parameter variable">-only_center_face</span>    Only restore the center face
  <span class="token parameter variable">-aligned</span>             Input are aligned faces
  <span class="token parameter variable">-ext</span>                 Image extension. Options: auto <span class="token operator">|</span> jpg <span class="token operator">|</span> png, auto means using the same extension as inputs. Default: auto
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Because <code>basicsr</code> and <code>facexlib</code> both depend on <code>torch</code>, you need to uninstall<code>torch</code>, and force to reinstall <code>pytorch-directml</code>: (<strong>Dependency relations will not be satisfied, but ok</strong>)</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>pip uninstall torch
pip <span class="token function">install</span> --force-reinstall pytorch-directml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>About Real-ESRGAN</p><p>The unoptimized RealESRGAN is slow on CPU. If you really want to use it on CPU, please modify the corresponding codes: (<code>inference_gfpgan.py</code> Line59)</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment"># ------------------------ set up background upsampler ------------------------</span>
<span class="token keyword">if</span> args<span class="token punctuation">.</span>bg_upsampler <span class="token operator">==</span> <span class="token string">&#39;realesrgan&#39;</span><span class="token punctuation">:</span>
    <span class="token keyword">from</span> basicsr<span class="token punctuation">.</span>archs<span class="token punctuation">.</span>rrdbnet_arch <span class="token keyword">import</span> RRDBNet
    <span class="token keyword">from</span> realesrgan <span class="token keyword">import</span> RealESRGANer
    model <span class="token operator">=</span> RRDBNet<span class="token punctuation">(</span>num_in_ch<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> num_out_ch<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> num_feat<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> num_block<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">,</span> num_grow_ch<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    bg_upsampler <span class="token operator">=</span> RealESRGANer<span class="token punctuation">(</span>
        scale<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
        model_path<span class="token operator">=</span><span class="token string">&#39;https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth&#39;</span><span class="token punctuation">,</span>
        model<span class="token operator">=</span>model<span class="token punctuation">,</span>
        tile<span class="token operator">=</span>args<span class="token punctuation">.</span>bg_tile<span class="token punctuation">,</span>
        tile_pad<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
        pre_pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
        half<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># use fp16, need to set False in CPU mode</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    bg_upsampler <span class="token operator">=</span> <span class="token boolean">None</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Everything is OK here.</strong></p></li>`,3),f=t(`<p>DirectML Support</p><p>In <code>inference_gfpgan.py</code>: add <code>device</code> parameter to constructors of <code>RealESRGANer</code> and <code>GFPGANer</code>.</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch_directml
dml <span class="token operator">=</span> torch_directml<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token punctuation">)</span>

bg_upsampler <span class="token operator">=</span> RealESRGANer<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> device<span class="token operator">=</span>dml<span class="token punctuation">)</span>
restorer <span class="token operator">=</span> GFPGANer<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> device<span class="token operator">=</span>dml<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>But there are currently two problems:</strong></p>`,4),w=t(`<li><p><code>upsampler</code> triggers an assertion in <code>basicsr\\archs\\arch_util.py</code> after processing several tiles, which is not solved:</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code>Assert that hh <span class="token operator">%</span> scale <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> hw <span class="token operator">%</span> scale <span class="token operator">==</span> <span class="token number">0</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li>`,1),y=n("p",null,[e("If "),n("code",null,"realesrgan"),e(" is disabled, the face can be processed normally, but result is very weird.")],-1),x=n("p",null,"In order to avoid discomfort, no results are shown here.",-1),G=n("p",null,"The CPU output are normal, but the DirectML output is abnormal.",-1),R={href:"https://github.com/microsoft/DirectML/issues/482",target:"_blank",rel:"noopener noreferrer"};function A(N,D){const s=p("ExternalLinkIcon");return l(),i("div",null,[c,d,u,n("p",null,[e("Now, Microsoft published "),n("a",m,[e("DirectML"),a(s)]),e(", which makes any GPU supporting DirectX12 be able to be used for DL on Windows.")]),v,n("p",null,[e("Choose "),n("a",h,[e("GFPGAN"),a(s)]),e(" from Tencent as an example, which aims at recover faces, with "),n("a",b,[e("Real-ESRGAN"),a(s)]),e(" built in, which can enhance the background.")]),n("ol",null,[n("li",null,[n("p",null,[e("Follow its "),n("a",k,[e("Guide"),a(s)]),e("\uFF1A")]),g]),_,n("li",null,[f,n("ul",null,[w,n("li",null,[y,x,G,n("p",null,[e("After analysis, the problem may be in the bilinear interpolation calculation, I have raised an issue in the DirectML project, "),n("a",R,[e("click here"),a(s)]),e(".")])])])])])])}const L=o(r,[["render",A],["__file","deep_learning_with_amd_gpu_on_windows.html.vue"]]);export{L as default};
